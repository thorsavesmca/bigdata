
========================================
========================================
**********   HIVE COMPLETE NOTES   **********
========================================
========================================

HOW TO START HIVE:
1. Start Cloudera QuickStart VM
2. Open Terminal
3. Start Hive Shell:
hive

----------------------------------------
1. CREATE DATABASE
----------------------------------------
CREATE DATABASE college;
SHOW DATABASES;
USE college;

----------------------------------------
2. CREATE TABLE
----------------------------------------
CREATE TABLE students(
  roll INT,
  name STRING,
  dept STRING,
  marks INT
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ',';

----------------------------------------
3. LOAD DATA INTO TABLE
----------------------------------------
LOAD DATA LOCAL INPATH 'student.txt' INTO TABLE students;

----------------------------------------
4. HIVE DATA TYPES
----------------------------------------
INT
STRING
FLOAT
DOUBLE
BOOLEAN
DATE
ARRAY
MAP
STRUCT

----------------------------------------
5. PARTITIONING
----------------------------------------
CREATE TABLE sales(
  id INT,
  amount INT
)
PARTITIONED BY (year INT, month INT)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ',';

ADD PARTITION:
ALTER TABLE sales ADD PARTITION (year=2024, month=11);

----------------------------------------
6. HIVE BUILT-IN OPERATORS
----------------------------------------
SELECT 5+3;
SELECT 'A' || 'B';
SELECT * FROM students WHERE marks > 70;

----------------------------------------
7. HIVE FUNCTIONS
----------------------------------------
SELECT upper(name) FROM students;
SELECT count(*) FROM students;
SELECT max(marks) FROM students;
SELECT substr(name,1,3) FROM students;
SELECT current_date;

----------------------------------------
8. HIVE VIEWS
----------------------------------------
CREATE VIEW high_scorers AS
SELECT name, marks FROM students WHERE marks > 80;

SELECT * FROM high_scorers;

----------------------------------------
9. HIVEQL (WHERE, ORDER BY, GROUP BY, JOIN)
----------------------------------------
WHERE:
SELECT * FROM students WHERE marks > 70;

ORDER BY:
SELECT * FROM students ORDER BY marks DESC;

GROUP BY:
SELECT dept, AVG(marks) FROM students GROUP BY dept;

JOIN:
SELECT s.name, d.dept_name
FROM students s
JOIN departments d
ON s.dept = d.id;



========================================
========================================
**********   SPARK SCALA (PAIR RDD)   **********
========================================
========================================

HOW TO START SPARK SHELL:
Open Terminal:
spark-shell

----------------------------------------
1. CREATE PAIR RDD
----------------------------------------
val data = Array(("A",10), ("B",20), ("A",5))
val rdd = sc.parallelize(data)

----------------------------------------
2. CREATE RDD FROM COLLECTION
----------------------------------------
val nums = sc.parallelize(List(1,2,3,4,5))

----------------------------------------
3. REDUCE BY KEY
----------------------------------------
val reduced = rdd.reduceByKey((x,y) => x+y)
reduced.collect()

----------------------------------------
4. READ TEXT FILE (HDFS)
----------------------------------------
val lines = sc.textFile("hdfs:///user/data/file.txt")

----------------------------------------
5. groupByKey
----------------------------------------
val grp = rdd.groupByKey()
grp.collect()

----------------------------------------
6. MAP TRANSFORMATION
----------------------------------------
val mapped = nums.map(x => x*2)

----------------------------------------
7. mapValues
----------------------------------------
val mv = rdd.mapValues(x => x*10)

----------------------------------------
8. FILTER TRANSFORMATION
----------------------------------------
val fil = nums.filter(x => x > 3)

----------------------------------------
9. sortByKey
----------------------------------------
val sorted = rdd.sortByKey()

----------------------------------------
10. REDUCE ACTION
----------------------------------------
nums.reduce((a,b)=>a+b)

----------------------------------------
11. JOIN
----------------------------------------
val rdd1 = sc.parallelize(Array((1,"A"), (2,"B")))
val rdd2 = sc.parallelize(Array((1,100), (2,200)))
val joined = rdd1.join(rdd2)

----------------------------------------
12. COLLECT ACTION
----------------------------------------
val data = rdd.collect()

----------------------------------------
13. COGROUP
----------------------------------------
val cg = rdd1.cogroup(rdd2)

----------------------------------------
14. SAVE RDD TO HDFS
----------------------------------------
rdd.saveAsTextFile("hdfs:///output/rddsave")

----------------------------------------
15. aggregateByKey
----------------------------------------
val agg = rdd.aggregateByKey(0)(
    (acc,value) => acc + value,
    (acc1,acc2) => acc1 + acc2
)

----------------------------------------
16. CACHE / PERSIST
----------------------------------------
val cached = rdd.cache()
val persisted = rdd.persist()

----------------------------------------
17. foldByKey
----------------------------------------
val fold = rdd.foldByKey(0)((acc,value) => acc+value)

----------------------------------------
18. READ FROM LOCAL FILE
----------------------------------------
val localfile = sc.textFile("file:///home/cloudera/local.txt")

========================================
=========  END OF NOTEPAD NOTES  =========
========================================

If you want, I can also give you:

✔ One combined PDF  
✔ One combined DOCX  
✔ Screenshot-style output folder  
✔ Viva questions for Hive, Pig & Spark  

Just tell me “make PDF” or “make DOCX”.
