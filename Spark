========================================
========================================
**********   SPARK SCALA (PAIR RDD)   **********
========================================
========================================

HOW TO START SPARK SHELL:
Open Terminal:
spark-shell

----------------------------------------
1. CREATE PAIR RDD
----------------------------------------
val data = Array(("A",10), ("B",20), ("A",5))
val rdd = sc.parallelize(data)

----------------------------------------
2. CREATE RDD FROM COLLECTION
----------------------------------------
val nums = sc.parallelize(List(1,2,3,4,5))

----------------------------------------
3. REDUCE BY KEY
----------------------------------------
val reduced = rdd.reduceByKey((x,y) => x+y)
reduced.collect()

----------------------------------------
4. READ TEXT FILE (HDFS)
----------------------------------------
val lines = sc.textFile("hdfs:///user/data/file.txt")

----------------------------------------
5. groupByKey
----------------------------------------
val grp = rdd.groupByKey()
grp.collect()

----------------------------------------
6. MAP TRANSFORMATION
----------------------------------------
val mapped = nums.map(x => x*2)

----------------------------------------
7. mapValues
----------------------------------------
val mv = rdd.mapValues(x => x*10)

----------------------------------------
8. FILTER TRANSFORMATION
----------------------------------------
val fil = nums.filter(x => x > 3)

----------------------------------------
9. sortByKey
----------------------------------------
val sorted = rdd.sortByKey()

----------------------------------------
10. REDUCE ACTION
----------------------------------------
nums.reduce((a,b)=>a+b)

----------------------------------------
11. JOIN
----------------------------------------
val rdd1 = sc.parallelize(Array((1,"A"), (2,"B")))
val rdd2 = sc.parallelize(Array((1,100), (2,200)))
val joined = rdd1.join(rdd2)

----------------------------------------
12. COLLECT ACTION
----------------------------------------
val data = rdd.collect()

----------------------------------------
13. COGROUP
----------------------------------------
val cg = rdd1.cogroup(rdd2)

----------------------------------------
14. SAVE RDD TO HDFS
----------------------------------------
rdd.saveAsTextFile("hdfs:///output/rddsave")

----------------------------------------
15. aggregateByKey
----------------------------------------
val agg = rdd.aggregateByKey(0)(
    (acc,value) => acc + value,
    (acc1,acc2) => acc1 + acc2
)

----------------------------------------
16. CACHE / PERSIST
----------------------------------------
val cached = rdd.cache()
val persisted = rdd.persist()

----------------------------------------
17. foldByKey
----------------------------------------
val fold = rdd.foldByKey(0)((acc,value) => acc+value)

----------------------------------------
18. READ FROM LOCAL FILE
----------------------------------------
val localfile = sc.textFile("file:///home/cloudera/local.txt")
